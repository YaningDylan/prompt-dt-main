{"_step": 4999, "test-evaluation/merged_cheetah_vel-1_target_0_return_std": 3.875355998816117, "train-evaluation/merged_cheetah_vel-2_target_0_return_mean": -26.167320604244825, "train-evaluation/merged_cheetah_vel-12_target_0_return_mean": -177.1429373291051, "_timestamp": 1721794944.7377152, "training/train_loss_std": 0.0023613625977276773, "train-evaluation/merged_cheetah_vel-2_target_0_return_std": 12.640700501491818, "train-evaluation/merged_cheetah_vel-6_target_0_return_mean": -100.20463850203382, "train-evaluation/merged_cheetah_vel-10_target_0_return_std": 53.29844764247408, "train-evaluation/merged_cheetah_vel-14_target_0_return_mean": -193.1980524066928, "test-evaluation/merged_cheetah_vel-11_target_0_return_std": 2.817513391739651, "train-evaluation/merged_cheetah_vel-4_target_0_return_mean": -75.21265940515501, "train-evaluation/merged_cheetah_vel-4_target_0_return_std": 3.2332713146225966, "time/training": 0.7484793663024902, "training/action_error": 0.12407249212265015, "test-evaluation/merged_cheetah_vel-1_target_0_return_mean": -34.23892109871534, "train-evaluation/merged_cheetah_vel-16_target_0_return_mean": -207.49450674997232, "test-evaluation/merged_cheetah_vel-11_target_0_return_mean": -165.5012291166545, "train-evaluation/merged_cheetah_vel-16_target_0_return_std": 4.624708879016199, "train-evaluation/merged_cheetah_vel-19_target_0_return_mean": -103.72470246075844, "train-evaluation/merged_cheetah_vel-0_target_0_return_mean": -34.79139703627494, "train-evaluation/merged_cheetah_vel-5_target_0_return_std": 12.422850665308601, "train-evaluation/merged_cheetah_vel-8_target_0_return_mean": -113.8898178913866, "train-evaluation/merged_cheetah_vel-17_target_0_return_std": 16.169462798716335, "test-evaluation/merged_cheetah_vel-13_target_0_return_mean": -186.97435612787987, "train-evaluation/merged_cheetah_vel-15_target_0_return_mean": -202.79303726199555, "train-evaluation/merged_cheetah_vel-9_target_0_return_mean": -127.55002560227675, "_runtime": 12309.57743525505, "train-evaluation/merged_cheetah_vel-17_target_0_return_mean": -235.6394556408203, "training/train_loss_mean": 0.12379398569464684, "train-evaluation/merged_cheetah_vel-0_target_0_return_std": 0.6405766114469206, "train-evaluation/merged_cheetah_vel-6_target_0_return_std": 4.310938133854983, "test-evaluation/merged_cheetah_vel-3_target_0_return_mean": -22.049042433271026, "train-evaluation/merged_cheetah_vel-19_target_0_return_std": 42.88431104426478, "test-evaluation/merged_cheetah_vel-7_target_0_return_mean": -86.44280958492372, "test-evaluation/merged_cheetah_vel-3_target_0_return_std": 11.080563853219731, "train-evaluation/merged_cheetah_vel-5_target_0_return_mean": -74.5205086830758, "train-evaluation/merged_cheetah_vel-8_target_0_return_std": 18.993181858790113, "train-evaluation/merged_cheetah_vel-18_target_0_return_mean": -187.584794217382, "time/evaluation": 104.50861692428589, "train-evaluation/merged_cheetah_vel-9_target_0_return_std": 6.696605996363484, "train-evaluation/merged_cheetah_vel-10_target_0_return_mean": -94.63306129753981, "global_step": 4999, "train-evaluation/merged_cheetah_vel-12_target_0_return_std": 4.198775091073082, "train-evaluation/merged_cheetah_vel-18_target_0_return_std": 14.54420819348232, "train-evaluation/merged_cheetah_vel-14_target_0_return_std": 7.299172919717909, "train-evaluation/merged_cheetah_vel-15_target_0_return_std": 4.975349138103801, "test-evaluation/merged_cheetah_vel-7_target_0_return_std": 2.8108103946978744, "test-evaluation/merged_cheetah_vel-13_target_0_return_std": 3.7818201297253116}
